{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## REPLACE NULL IPPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "file_name='DataFull.xlsx'\n",
    "\n",
    "df = pd.read_excel(file_name, sheet_name='Sheet1')\n",
    "df['IPP'] = df['IPP'].astype('str') \n",
    "df['IPP']= df['IPP'].replace(['pasIPP','nan'],np.NaN)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GENERATE RANDOM IPPS AND REPLACE NULL IPPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "pattern=r'^[0-9]+$'\n",
    "#df['IPP'] = df['IPP'].astype('str') \n",
    "#df.IPP.str.match(pattern,na=False)\n",
    "list_ipps=df[df.IPP.str.match(pattern,na=False)]['IPP'].tolist()\n",
    "count_null_ipps=df['IPP'].shape[0]-len(list_ipps)\n",
    "new_ipps=[]\n",
    "#generate ipp that doesn't match ipp in the list_ipp or new_ipps\n",
    "x=0\n",
    "for x in range (0,count_null_ipps):\n",
    "    while True:\n",
    "        generated_ipp=random.randint(1,5000)\n",
    "        if generated_ipp not in list_ipps and generated_ipp not in new_ipps:\n",
    "            new_ipps.append(str(generated_ipp))\n",
    "            break;\n",
    "    x=x+1\n",
    "\n",
    "#assign patient with null ipp ,the new ipp\n",
    "df.loc[df.IPP.isna(),'IPP'] = new_ipps\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ENCODE PATIENTS USING IPPS AND MD5 HASH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib\n",
    "\n",
    "df['hash_ipp']=df['IPP'].str.encode('utf-8').apply(lambda x: hashlib.md5(x).hexdigest())\n",
    "\n",
    "df=df.drop(['PATIENT','REF_NAME','REF_ID770S4V3638','REF_SURNAME','NAME','SURNAME','NO','IPP','Column1'],1)\n",
    "cols = df.columns.tolist()\n",
    "cols = cols[-1:] + cols[:-1]\n",
    "df = df[cols] \n",
    "\n",
    "df.to_excel('Data.xlsx',encoding='utf-8-sig',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRANSFORM STRUCTURE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_name='Data.xlsx'\n",
    "#file_name='Data10_07.xlsx'\n",
    "\n",
    "df_A=pd.DataFrame()\n",
    "df_B=pd.DataFrame()\n",
    "df_C=pd.DataFrame()\n",
    "df_D=pd.DataFrame()\n",
    "\n",
    "#create lists to hold headers & other variables\n",
    "HEADERS = []\n",
    "DATES_EXAM = []\n",
    "HEIGHTS=[]\n",
    "WEIGHTS_REF=[]\n",
    "WEIGHTS=[]\n",
    "BMIS=[]\n",
    "ALS=[]\n",
    "ALS_PARO=[]\n",
    "ALS_SALI =[]\n",
    "ALS_DEGL=[] \n",
    "ALS_ERCI=[] \n",
    "ALS_SGAS=[] \n",
    "ALS_AGAS=[] \n",
    "ALS_HABI=[] \n",
    "ALS_LITD=[]\n",
    "ALS_MARC=[] \n",
    "ALS_ESCA =[]\n",
    "ALS_DYSPNE=[] \n",
    "ALS_ORTHOPNE=[] \n",
    "ALS_INSR=[]\n",
    "DATES_RILUZ=[]\n",
    "DATES_PREVENT=[]\n",
    "CVF_ASSIS_THEO=[]\n",
    "CVL_ASSIS_THEO=[]\n",
    "DATES_DECES=[]\n",
    "All_cols=[]\n",
    "#group variables\n",
    "\n",
    "info=['hash_ipp','SEX','DOB','DIAGPROBA','DATEDIAG','FIRSTSYMPTOM','LIEUDEB','AGE_DEBUT']\n",
    "clinical_measures_1=['DATEXAM','HEIGHT','WEIGHT_REF','WEIGHT','BMI','ALS','ALS_PARO','ALS_SALI','ALS_DEGL','ALS_ERCI','ALS_SGAS','ALS_AGAS','ALS_HABI','ALS_LITD','ALS_MARC','ALS_ESCA','ALS_ALS_dyspne','ALS_ALS_orthopne','ALS_INSR']\n",
    "clinical_measures_2=['DATE_PREVENT_PP','CVF_ASSIS_THEO_PP','CVL_ASSIS_THEO_PP']\n",
    "clinical_measures_riluz_1=['DATDRILU_L1']\n",
    "clinical_measures_deces=['DATEDCD']\n",
    "\n",
    "\n",
    "#Read CSV File\n",
    "df = pd.read_excel(file_name, sheet_name='Sheet1')\n",
    "\n",
    "#create a list of all the columns\n",
    "columns = list(df)\n",
    "\n",
    "#split columns list into headers and other variables\n",
    "for col in columns:\n",
    "    if col.startswith('DATEXAM'):\n",
    "        DATES_EXAM.append(col)\n",
    "    elif  col.startswith('HEIGHT'):\n",
    "        HEIGHTS.append(col)\n",
    "    elif col.startswith('WEIGHT_REF') :\n",
    "        WEIGHTS_REF.append(col)\n",
    "    elif  col.startswith('WEIGHT') :\n",
    "        WEIGHTS.append(col)\n",
    "    elif   col.startswith('BMI'): \n",
    "        BMIS.append(col)\n",
    "    elif  col.startswith('DATDRILU'):\n",
    "        DATES_RILUZ.append(col)\n",
    "    elif col.startswith('DATE_PREVENT'):\n",
    "        DATES_PREVENT.append(col)\n",
    "    elif col.startswith('CVF_ASSIS_THEO'):\n",
    "        CVF_ASSIS_THEO.append(col)\n",
    "    elif col.startswith('CVL_ASSIS_THEO'):\n",
    "        CVL_ASSIS_THEO.append(col)\n",
    "    elif col.startswith('DATEDCD'):\n",
    "        DATES_DECES.append(col)\n",
    "    elif  col.startswith('ALS'):\n",
    "        ##\n",
    "        if col.__contains__('PARO'):\n",
    "            ALS_PARO.append(col)\n",
    "        elif col.__contains__('SALI'):\n",
    "            ALS_SALI.append(col)\n",
    "        elif  col.__contains__('DEGL'):\n",
    "            ALS_DEGL.append(col)\n",
    "        elif  col.__contains__('ERCI'):\n",
    "            ALS_ERCI.append(col)\n",
    "        elif  col.__contains__('SGAS') :\n",
    "            ALS_SGAS.append(col)\n",
    "        elif  col.__contains__('AGAS'):\n",
    "            ALS_AGAS.append(col)\n",
    "        elif col.__contains__('HABI') :\n",
    "            ALS_HABI.append(col)\n",
    "        elif col.__contains__('LITD') :\n",
    "            ALS_LITD.append(col)\n",
    "        elif  col.__contains__('MARC') :\n",
    "            ALS_MARC.append(col)\n",
    "        elif  col.__contains__('ESCA'):\n",
    "            ALS_ESCA.append(col)\n",
    "        elif  col.__contains__('dyspne'):\n",
    "            ALS_DYSPNE.append(col)\n",
    "        elif col.__contains__('orthopne'):\n",
    "            ALS_ORTHOPNE.append(col)\n",
    "        elif col.__contains__('INSR'):\n",
    "            ALS_INSR.append(col)\n",
    "        else :\n",
    "            ALS.append(col)\n",
    "    else:\n",
    "        HEADERS.append(col)\n",
    "\n",
    "#For headers take into account only info \n",
    "\n",
    "HEADERS=list( x for x in info )\n",
    "\n",
    "#group column variables\n",
    "All_cols=[]\n",
    "All_cols.append(DATES_EXAM)\n",
    "All_cols.append(HEIGHTS)\n",
    "All_cols.append(WEIGHTS_REF)\n",
    "All_cols.append(WEIGHTS)\n",
    "All_cols.append(BMIS)\n",
    "All_cols.append(ALS)\n",
    "All_cols.append(ALS_PARO)\n",
    "All_cols.append(ALS_SALI)\n",
    "All_cols.append(ALS_DEGL)\n",
    "All_cols.append(ALS_ERCI)\n",
    "All_cols.append(ALS_SGAS)\n",
    "All_cols.append(ALS_AGAS)\n",
    "All_cols.append(ALS_HABI)\n",
    "All_cols.append(ALS_LITD)\n",
    "All_cols.append(ALS_MARC)\n",
    "All_cols.append(ALS_ESCA)\n",
    "All_cols.append(ALS_DYSPNE)\n",
    "All_cols.append(ALS_ORTHOPNE)\n",
    "All_cols.append(ALS_INSR)\n",
    "All_cols.append(DATES_RILUZ)\n",
    "All_cols.append(DATES_PREVENT)\n",
    "All_cols.append(CVF_ASSIS_THEO)\n",
    "All_cols.append(CVL_ASSIS_THEO)\n",
    "All_cols.append(DATES_DECES)\n",
    "\n",
    "#remove empty lists from All_cols list if exist \n",
    "All_cols = [x for x in All_cols if x != []]\n",
    "\n",
    "#Create a final DF with modified columns\n",
    "for lst in All_cols:\n",
    "    df_x = pd.melt(df,\n",
    "                  id_vars=HEADERS,\n",
    "                  value_vars=lst,\n",
    "                  var_name=lst[0],\n",
    "                  value_name=lst[0]+'_VALUE')\n",
    "         #Concatenate DataFrames 1\n",
    "    if any(elem in lst for elem in clinical_measures_1):\n",
    "        df_A= pd.concat([df_A, df_x],axis=1)\n",
    "    if any(elem in lst for elem in clinical_measures_riluz_1):\n",
    "        #Concatenate DataFrames 2\n",
    "        df_B= pd.concat([df_B, df_x],axis=1)\n",
    "    if any(elem in lst for elem in clinical_measures_2):\n",
    "        #Concatenate DataFrames 3\n",
    "        df_C= pd.concat([df_C, df_x],axis=1)\n",
    "    if any(elem in lst for elem in clinical_measures_deces):\n",
    "        df_D=pd.concat([df_D,df_x],axis=1)\n",
    "        \n",
    "#Delete duplicate columns\n",
    "df_A= df_A.loc[:, ~df_A.columns.duplicated()]\n",
    "df_B= df_B.loc[:, ~df_B.columns.duplicated()]\n",
    "df_C= df_C.loc[:, ~df_C.columns.duplicated()]\n",
    "df_D=df_D.loc[:, ~df_D.columns.duplicated()]\n",
    "\n",
    "#Write Dataframes to csv\n",
    "df_A.to_csv(\"df_clinical_measures_1.csv\",index=False,encoding='utf-8-sig')\n",
    "df_B.to_csv(\"df_clinical_measures_1_Date_Riluzole.csv\",index=False,encoding='utf-8-sig')\n",
    "df_C.to_csv(\"df_clinical_measures_2.csv\",index=False,encoding='utf-8-sig')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
