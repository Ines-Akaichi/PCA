{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## REPLACE NULL IPPS BY np.NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "file_name1='DataFull.xlsx'\n",
    "file_name2='Data10_07.xlsx'\n",
    "sheet_name='Sheet1'\n",
    "\n",
    "def Replace_Null_Ipp(file_name, sheet_name):\n",
    "    df = pd.read_excel(file_name, sheet_name)\n",
    "    df['IPP'] = df['IPP'].astype('str') \n",
    "    df['IPP']= df['IPP'].replace(['pasIPP','nan'],np.NaN)\n",
    "    return df\n",
    "\n",
    "df1=Replace_Null_Ipp(file_name1,sheet_name)\n",
    "df2=Replace_Null_Ipp(file_name2,sheet_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ENCODE PATIENTS USING IPPS AND MD5 HASH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib\n",
    "\n",
    "\n",
    "def Encode_Patients(df):\n",
    "    for index, row in df.iterrows():\n",
    "        if row['IPP'] is not None:\n",
    "             df.loc[index,'IPP_HASH']=hashlib.md5(str(row['IPP']).encode(\"utf-8\")).hexdigest()\n",
    "        else:\n",
    "             df.loc[index,'IPP_HASH']=hashlib.md5(str(row['NAME']+row['SURNAME']+row['DOB']).encode(\"utf-8\")).hexdigest()\n",
    "\n",
    "\n",
    "    df=df.drop(['PATIENT','REF_NAME','REF_ID770S4V3638','REF_SURNAME','NAME','SURNAME','NO','IPP','Column1'],1)\n",
    "    cols = df.columns.tolist()\n",
    "    cols = cols[-1:] + cols[:-1]\n",
    "    df = df[cols] \n",
    "    return df\n",
    "\n",
    "\n",
    "df1=Encode_Patients(df1)\n",
    "df2=Encode_Patients(df2)\n",
    "\n",
    "df1.to_excel('Data.xlsx',encoding='utf-8-sig',index=False)\n",
    "df2.to_excel('Data_x.xlsx',encoding='utf-8-sig',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRANSFORM STRUCTURE OF DATA.XLSX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_name='Data.xlsx'\n",
    "\n",
    "df_A=pd.DataFrame()\n",
    "df_B=pd.DataFrame()\n",
    "df_C=pd.DataFrame()\n",
    "\n",
    "#create lists to hold headers & other variables\n",
    "HEADERS = []\n",
    "DATES_EXAM = []\n",
    "HEIGHTS=[]\n",
    "WEIGHTS_REF=[]\n",
    "WEIGHTS=[]\n",
    "BMIS=[]\n",
    "ALS=[]\n",
    "ALS_PARO=[]\n",
    "ALS_SALI =[]\n",
    "ALS_DEGL=[] \n",
    "ALS_ERCI=[] \n",
    "ALS_SGAS=[] \n",
    "ALS_AGAS=[] \n",
    "ALS_HABI=[] \n",
    "ALS_LITD=[]\n",
    "ALS_MARC=[] \n",
    "ALS_ESCA =[]\n",
    "ALS_DYSPNE=[] \n",
    "ALS_ORTHOPNE=[] \n",
    "ALS_INSR=[]\n",
    "DATES_RILUZ=[]\n",
    "DATES_PREVENT=[]\n",
    "CVF_ASSIS_THEO=[]\n",
    "CVL_ASSIS_THEO=[]\n",
    "All_cols=[]\n",
    "#group variables\n",
    "\n",
    "info=['IPP_HASH','SEX','DOB','DIAGPROBA','DATEDIAG','FIRSTSYMPTOM','LIEUDEB','AGE_DEBUT']\n",
    "clinical_measures_1=['DATEXAM','HEIGHT','WEIGHT_REF','WEIGHT','BMI','ALS','ALS_PARO','ALS_SALI','ALS_DEGL','ALS_ERCI','ALS_SGAS','ALS_AGAS','ALS_HABI','ALS_LITD','ALS_MARC','ALS_ESCA','ALS_ALS_dyspne','ALS_ALS_orthopne','ALS_INSR']\n",
    "clinical_measures_2=['DATE_PREVENT_PP','CVF_ASSIS_THEO_PP','CVL_ASSIS_THEO_PP']\n",
    "clinical_measures_riluz_1=['DATDRILU_L1']\n",
    "\n",
    "\n",
    "\n",
    "#Read CSV File\n",
    "df = pd.read_excel(file_name, sheet_name='Sheet1')\n",
    "\n",
    "#create a list of all the columns\n",
    "columns = list(df)\n",
    "\n",
    "#split columns list into headers and other variables\n",
    "for col in columns:\n",
    "    if col.startswith('DATEXAM'):\n",
    "        DATES_EXAM.append(col)\n",
    "    elif  col.startswith('HEIGHT'):\n",
    "        HEIGHTS.append(col)\n",
    "    elif col.startswith('WEIGHT_REF') :\n",
    "        WEIGHTS_REF.append(col)\n",
    "    elif  col.startswith('WEIGHT') :\n",
    "        WEIGHTS.append(col)\n",
    "    elif   col.startswith('BMI'): \n",
    "        BMIS.append(col)\n",
    "    elif  col.startswith('DATDRILU'):\n",
    "        DATES_RILUZ.append(col)\n",
    "    elif col.startswith('DATE_PREVENT'):\n",
    "        DATES_PREVENT.append(col)\n",
    "    elif col.startswith('CVF_ASSIS_THEO'):\n",
    "        CVF_ASSIS_THEO.append(col)\n",
    "    elif col.startswith('CVL_ASSIS_THEO'):\n",
    "        CVL_ASSIS_THEO.append(col)\n",
    "    elif  col.startswith('ALS'):\n",
    "        ##\n",
    "        if col.__contains__('PARO'):\n",
    "            ALS_PARO.append(col)\n",
    "        elif col.__contains__('SALI'):\n",
    "            ALS_SALI.append(col)\n",
    "        elif  col.__contains__('DEGL'):\n",
    "            ALS_DEGL.append(col)\n",
    "        elif  col.__contains__('ERCI'):\n",
    "            ALS_ERCI.append(col)\n",
    "        elif  col.__contains__('SGAS') :\n",
    "            ALS_SGAS.append(col)\n",
    "        elif  col.__contains__('AGAS'):\n",
    "            ALS_AGAS.append(col)\n",
    "        elif col.__contains__('HABI') :\n",
    "            ALS_HABI.append(col)\n",
    "        elif col.__contains__('LITD') :\n",
    "            ALS_LITD.append(col)\n",
    "        elif  col.__contains__('MARC') :\n",
    "            ALS_MARC.append(col)\n",
    "        elif  col.__contains__('ESCA'):\n",
    "            ALS_ESCA.append(col)\n",
    "        elif  col.__contains__('dyspne'):\n",
    "            ALS_DYSPNE.append(col)\n",
    "        elif col.__contains__('orthopne'):\n",
    "            ALS_ORTHOPNE.append(col)\n",
    "        elif col.__contains__('INSR'):\n",
    "            ALS_INSR.append(col)\n",
    "        else :\n",
    "            ALS.append(col)\n",
    "    else:\n",
    "        HEADERS.append(col)\n",
    "\n",
    "#For headers take into account only info \n",
    "\n",
    "HEADERS=list( x for x in info )\n",
    "\n",
    "#group column variables\n",
    "All_cols=[]\n",
    "All_cols.append(DATES_EXAM)\n",
    "All_cols.append(HEIGHTS)\n",
    "All_cols.append(WEIGHTS_REF)\n",
    "All_cols.append(WEIGHTS)\n",
    "All_cols.append(BMIS)\n",
    "All_cols.append(ALS)\n",
    "All_cols.append(ALS_PARO)\n",
    "All_cols.append(ALS_SALI)\n",
    "All_cols.append(ALS_DEGL)\n",
    "All_cols.append(ALS_ERCI)\n",
    "All_cols.append(ALS_SGAS)\n",
    "All_cols.append(ALS_AGAS)\n",
    "All_cols.append(ALS_HABI)\n",
    "All_cols.append(ALS_LITD)\n",
    "All_cols.append(ALS_MARC)\n",
    "All_cols.append(ALS_ESCA)\n",
    "All_cols.append(ALS_DYSPNE)\n",
    "All_cols.append(ALS_ORTHOPNE)\n",
    "All_cols.append(ALS_INSR)\n",
    "All_cols.append(DATES_RILUZ)\n",
    "All_cols.append(DATES_PREVENT)\n",
    "All_cols.append(CVF_ASSIS_THEO)\n",
    "All_cols.append(CVL_ASSIS_THEO)\n",
    "\n",
    "#remove empty lists from All_cols list if exist \n",
    "All_cols = [x for x in All_cols if x != []]\n",
    "\n",
    "#Create a final DF with modified columns\n",
    "for lst in All_cols:\n",
    "    df_x = pd.melt(df,\n",
    "                  id_vars=HEADERS,\n",
    "                  value_vars=lst,\n",
    "                  var_name=lst[0],\n",
    "                  value_name=lst[0]+'_VALUE')\n",
    "         #Concatenate DataFrames 1\n",
    "    if any(elem in lst for elem in clinical_measures_1):\n",
    "        df_A= pd.concat([df_A, df_x],axis=1)\n",
    "    if any(elem in lst for elem in clinical_measures_riluz_1):\n",
    "        #Concatenate DataFrames 2\n",
    "        df_B= pd.concat([df_B, df_x],axis=1)\n",
    "    if any(elem in lst for elem in clinical_measures_2):\n",
    "        df_C= pd.concat([df_C, df_x],axis=1)\n",
    "\n",
    "#Delete duplicate columns\n",
    "df_A= df_A.loc[:, ~df_A.columns.duplicated()]\n",
    "df_B= df_B.loc[:, ~df_B.columns.duplicated()]\n",
    "df_C= df_C.loc[:, ~df_C.columns.duplicated()]\n",
    "\n",
    "#Write Dataframes to csv\n",
    "df_A.to_csv(\"df_clinical_measures_1.csv\",index=False,encoding='utf-8-sig')\n",
    "df_B.to_csv(\"df_clinical_measures_1_Date_Riluzole.csv\",index=False,encoding='utf-8-sig')\n",
    "df_C.to_csv(\"df_clinical_measures_2.csv\",index=False,encoding='utf-8-sig')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRANSFORM STRUCTURE OF DATA_X.XLSX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1472: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "https://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate-loc-reindex-listlike\n",
      "  return self._getitem_tuple(key)\n"
     ]
    }
   ],
   "source": [
    "file_name='Data_x.xlsx'\n",
    "\n",
    "df_D=pd.DataFrame()\n",
    "\n",
    "#create lists to hold headers & other variables\n",
    "HEADERS = []\n",
    "DATES_DECES=[]\n",
    "All_cols=[]\n",
    "\n",
    "#group variables\n",
    "info=['IPP_HASH','SEX','DOB','DIAGPROBA','DATEDIAG','FIRSTSYMPTOM','LIEUDEB','AGE_DEBUT']\n",
    "clinical_measures_deces=['DATEDCD']\n",
    "\n",
    "\n",
    "#Read CSV File\n",
    "df = pd.read_excel(file_name, sheet_name='Sheet1')\n",
    "\n",
    "#create a list of all the columns\n",
    "columns = list(df)\n",
    "\n",
    "#split columns list into headers and other variables\n",
    "for col in columns:\n",
    "    if col.startswith('DATEDCD'):\n",
    "        DATES_DECES.append(col)\n",
    "    else:\n",
    "        HEADERS.append(col)\n",
    "\n",
    "#For headers take into account only info \n",
    "\n",
    "HEADERS=list( x for x in info )\n",
    "\n",
    "#group column variables\n",
    "All_cols=[]\n",
    "All_cols.append(DATES_DECES)\n",
    "\n",
    "#remove empty lists from All_cols list if exist \n",
    "All_cols = [x for x in All_cols if x != []]\n",
    "\n",
    "#Create a final DF with modified columns\n",
    "for lst in All_cols:\n",
    "    df_x = pd.melt(df,\n",
    "                  id_vars=HEADERS,\n",
    "                  value_vars=lst,\n",
    "                  var_name=lst[0],\n",
    "                  value_name=lst[0]+'_VALUE')\n",
    "         #Concatenate DataFrames\n",
    "    if any(elem in lst for elem in clinical_measures_deces):\n",
    "        df_D=pd.concat([df_D,df_x],axis=1)\n",
    "        \n",
    "#Delete duplicate columns\n",
    "df_D=df_D.loc[:, ~df_D.columns.duplicated()]\n",
    "\n",
    "#Write Dataframes to csv\n",
    "df_D.to_csv(\"df_clinical_measures_1_Date_Deces.csv\",index=False,encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
