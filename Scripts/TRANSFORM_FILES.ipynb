{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name1='D:\\StageMai2019\\Project\\data\\In\\FullData.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_name1='D:\\StageMai2019\\Project\\data\\In\\FullData.xlsx'\n",
    "df = pd.read_excel(file_name1, sheet_name='Sheet1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "file_name1='D:\\StageMai2019\\Project\\data\\In\\FullData.xlsx'\n",
    "file_name2='D:\\StageMai2019\\Project\\data\\In\\AdditionalData.xlsx'\n",
    "sheet_name='Sheet1'\n",
    "\n",
    "def Replace_Null_Ipp(file_name, sheet_name):\n",
    "    df = pd.read_excel(file_name, sheet_name)\n",
    "    df['IPP'] = df['IPP'].astype('str') \n",
    "    df['IPP']= df['IPP'].replace(['pasIPP','nan'],np.NaN)\n",
    "    return df\n",
    "\n",
    "df1=Replace_Null_Ipp(file_name1,sheet_name)\n",
    "df2=Replace_Null_Ipp(file_name2,sheet_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib\n",
    "\n",
    "\n",
    "def Encode_Patients(df):\n",
    "    for index, row in df.iterrows():\n",
    "        if row['IPP'] is not None:\n",
    "             df.loc[index,'IPP_HASH']=hashlib.md5(str(row['IPP']).encode(\"utf-8\")).hexdigest()\n",
    "        else:\n",
    "             df.loc[index,'IPP_HASH']=hashlib.md5(str(row['NAME']+row['SURNAME']+row['DOB']).encode(\"utf-8\")).hexdigest()\n",
    "\n",
    "\n",
    "    df=df.drop(['PATIENT','REF_NAME','REF_ID770S4V3638','REF_SURNAME','NAME','SURNAME','NO','IPP','Column1'],1)\n",
    "    cols = df.columns.tolist()\n",
    "    cols = cols[-1:] + cols[:-1]\n",
    "    df = df[cols] \n",
    "    return df\n",
    "\n",
    "\n",
    "df1=Encode_Patients(df1)\n",
    "df2=Encode_Patients(df2)\n",
    "\n",
    "df1.to_excel('FullData_Hashed.xlsx',encoding='utf-8-sig',index=False)\n",
    "df2.to_excel('AdditionalData_Hashed.xlsx',encoding='utf-8-sig',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_name='FullData_Hashed.xlsx'\n",
    "\n",
    "df_A=pd.DataFrame()\n",
    "df_B=pd.DataFrame()\n",
    "df_C=pd.DataFrame()\n",
    "\n",
    "#create lists to hold headers & other variables\n",
    "HEADERS = []\n",
    "DATES_EXAM = []\n",
    "HEIGHTS=[]\n",
    "WEIGHTS_REF=[]\n",
    "WEIGHTS=[]\n",
    "BMIS=[]\n",
    "ALS=[]\n",
    "ALS_PARO=[]\n",
    "ALS_SALI =[]\n",
    "ALS_DEGL=[] \n",
    "ALS_ERCI=[] \n",
    "ALS_SGAS=[] \n",
    "ALS_AGAS=[] \n",
    "ALS_HABI=[] \n",
    "ALS_LITD=[]\n",
    "ALS_MARC=[] \n",
    "ALS_ESCA =[]\n",
    "ALS_DYSPNE=[] \n",
    "ALS_ORTHOPNE=[] \n",
    "ALS_INSR=[]\n",
    "DATES_RILUZ=[]\n",
    "DATES_PREVENT=[]\n",
    "CVF_ASSIS_THEO=[]\n",
    "CVL_ASSIS_THEO=[]\n",
    "All_cols=[]\n",
    "#group variables\n",
    "\n",
    "info=['IPP_HASH','SEX','DOB','DIAGPROBA','DATEDIAG','FIRSTSYMPTOM','LIEUDEB','AGE_DEBUT']\n",
    "clinical_measures_1=['DATEXAM','HEIGHT','WEIGHT_REF','WEIGHT','BMI','ALS','ALS_PARO','ALS_SALI','ALS_DEGL','ALS_ERCI','ALS_SGAS','ALS_AGAS','ALS_HABI','ALS_LITD','ALS_MARC','ALS_ESCA','ALS_ALS_dyspne','ALS_ALS_orthopne','ALS_INSR']\n",
    "clinical_measures_2=['DATE_PREVENT_PP','CVF_ASSIS_THEO_PP','CVL_ASSIS_THEO_PP']\n",
    "clinical_measures_riluz_1=['DATDRILU_L1']\n",
    "\n",
    "\n",
    "\n",
    "#Read CSV File\n",
    "df = pd.read_excel(file_name, sheet_name='Sheet1')\n",
    "\n",
    "#create a list of all the columns\n",
    "columns = list(df)\n",
    "\n",
    "#split columns list into headers and other variables\n",
    "for col in columns:\n",
    "    if col.startswith('DATEXAM'):\n",
    "        DATES_EXAM.append(col)\n",
    "    elif  col.startswith('HEIGHT'):\n",
    "        HEIGHTS.append(col)\n",
    "    elif col.startswith('WEIGHT_REF') :\n",
    "        WEIGHTS_REF.append(col)\n",
    "    elif  col.startswith('WEIGHT') :\n",
    "        WEIGHTS.append(col)\n",
    "    elif   col.startswith('BMI'): \n",
    "        BMIS.append(col)\n",
    "    elif  col.startswith('DATDRILU'):\n",
    "        DATES_RILUZ.append(col)\n",
    "    elif col.startswith('DATE_PREVENT'):\n",
    "        DATES_PREVENT.append(col)\n",
    "    elif col.startswith('CVF_ASSIS_THEO'):\n",
    "        CVF_ASSIS_THEO.append(col)\n",
    "    elif col.startswith('CVL_ASSIS_THEO'):\n",
    "        CVL_ASSIS_THEO.append(col)\n",
    "    elif  col.startswith('ALS'):\n",
    "        ##\n",
    "        if col.__contains__('PARO'):\n",
    "            ALS_PARO.append(col)\n",
    "        elif col.__contains__('SALI'):\n",
    "            ALS_SALI.append(col)\n",
    "        elif  col.__contains__('DEGL'):\n",
    "            ALS_DEGL.append(col)\n",
    "        elif  col.__contains__('ERCI'):\n",
    "            ALS_ERCI.append(col)\n",
    "        elif  col.__contains__('SGAS') :\n",
    "            ALS_SGAS.append(col)\n",
    "        elif  col.__contains__('AGAS'):\n",
    "            ALS_AGAS.append(col)\n",
    "        elif col.__contains__('HABI') :\n",
    "            ALS_HABI.append(col)\n",
    "        elif col.__contains__('LITD') :\n",
    "            ALS_LITD.append(col)\n",
    "        elif  col.__contains__('MARC') :\n",
    "            ALS_MARC.append(col)\n",
    "        elif  col.__contains__('ESCA'):\n",
    "            ALS_ESCA.append(col)\n",
    "        elif  col.__contains__('dyspne'):\n",
    "            ALS_DYSPNE.append(col)\n",
    "        elif col.__contains__('orthopne'):\n",
    "            ALS_ORTHOPNE.append(col)\n",
    "        elif col.__contains__('INSR'):\n",
    "            ALS_INSR.append(col)\n",
    "        else :\n",
    "            ALS.append(col)\n",
    "    else:\n",
    "        HEADERS.append(col)\n",
    "\n",
    "#For headers take into account only info \n",
    "\n",
    "HEADERS=list( x for x in info )\n",
    "\n",
    "#group column variables\n",
    "All_cols=[]\n",
    "All_cols.append(DATES_EXAM)\n",
    "All_cols.append(HEIGHTS)\n",
    "All_cols.append(WEIGHTS_REF)\n",
    "All_cols.append(WEIGHTS)\n",
    "All_cols.append(BMIS)\n",
    "All_cols.append(ALS)\n",
    "All_cols.append(ALS_PARO)\n",
    "All_cols.append(ALS_SALI)\n",
    "All_cols.append(ALS_DEGL)\n",
    "All_cols.append(ALS_ERCI)\n",
    "All_cols.append(ALS_SGAS)\n",
    "All_cols.append(ALS_AGAS)\n",
    "All_cols.append(ALS_HABI)\n",
    "All_cols.append(ALS_LITD)\n",
    "All_cols.append(ALS_MARC)\n",
    "All_cols.append(ALS_ESCA)\n",
    "All_cols.append(ALS_DYSPNE)\n",
    "All_cols.append(ALS_ORTHOPNE)\n",
    "All_cols.append(ALS_INSR)\n",
    "All_cols.append(DATES_RILUZ)\n",
    "All_cols.append(DATES_PREVENT)\n",
    "All_cols.append(CVF_ASSIS_THEO)\n",
    "All_cols.append(CVL_ASSIS_THEO)\n",
    "\n",
    "#remove empty lists from All_cols list if exist \n",
    "All_cols = [x for x in All_cols if x != []]\n",
    "\n",
    "#Create a final DF with modified columns\n",
    "for lst in All_cols:\n",
    "    df_x = pd.melt(df,\n",
    "                  id_vars=HEADERS,\n",
    "                  value_vars=lst,\n",
    "                  var_name=lst[0],\n",
    "                  value_name=lst[0]+'_VALUE')\n",
    "         #Concatenate DataFrames 1\n",
    "    if any(elem in lst for elem in clinical_measures_1):\n",
    "        df_A= pd.concat([df_A, df_x],axis=1)\n",
    "    if any(elem in lst for elem in clinical_measures_riluz_1):\n",
    "        #Concatenate DataFrames 2\n",
    "        df_B= pd.concat([df_B, df_x],axis=1)\n",
    "    if any(elem in lst for elem in clinical_measures_2):\n",
    "        df_C= pd.concat([df_C, df_x],axis=1)\n",
    "\n",
    "#Delete duplicate columns\n",
    "df_A= df_A.loc[:, ~df_A.columns.duplicated()]\n",
    "df_B= df_B.loc[:, ~df_B.columns.duplicated()]\n",
    "df_C= df_C.loc[:, ~df_C.columns.duplicated()]\n",
    "\n",
    "#Write Dataframes to csv\n",
    "df_A.to_csv(\"df_clinical_measures_1.csv\",index=False,encoding='utf-8-sig')\n",
    "df_B.to_csv(\"df_clinical_measures_1_Date_Riluzole.csv\",index=False,encoding='utf-8-sig')\n",
    "df_C.to_csv(\"df_clinical_measures_2.csv\",index=False,encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name='AdditionalData_Hashed.xlsx'\n",
    "\n",
    "df_D=pd.DataFrame()\n",
    "\n",
    "#create lists to hold headers & other variables\n",
    "HEADERS = []\n",
    "DATES_DECES=[]\n",
    "All_cols=[]\n",
    "\n",
    "#group variables\n",
    "info=['IPP_HASH','SEX','DOB','DIAGPROBA','DATEDIAG','FIRSTSYMPTOM','LIEUDEB','AGE_DEBUT']\n",
    "clinical_measures_deces=['DATEDCD']\n",
    "\n",
    "\n",
    "#Read CSV File\n",
    "df = pd.read_excel(file_name, sheet_name='Sheet1')\n",
    "\n",
    "#create a list of all the columns\n",
    "columns = list(df)\n",
    "\n",
    "#split columns list into headers and other variables\n",
    "for col in columns:\n",
    "    if col.startswith('DATEDCD'):\n",
    "        DATES_DECES.append(col)\n",
    "    else:\n",
    "        HEADERS.append(col)\n",
    "\n",
    "#For headers take into account only info \n",
    "\n",
    "HEADERS=list( x for x in info )\n",
    "\n",
    "#group column variables\n",
    "All_cols=[]\n",
    "All_cols.append(DATES_DECES)\n",
    "\n",
    "#remove empty lists from All_cols list if exist \n",
    "All_cols = [x for x in All_cols if x != []]\n",
    "\n",
    "#Create a final DF with modified columns\n",
    "for lst in All_cols:\n",
    "    df_x = pd.melt(df,\n",
    "                  id_vars=HEADERS,\n",
    "                  value_vars=lst,\n",
    "                  var_name=lst[0],\n",
    "                  value_name=lst[0]+'_VALUE')\n",
    "         #Concatenate DataFrames\n",
    "    if any(elem in lst for elem in clinical_measures_deces):\n",
    "        df_D=pd.concat([df_D,df_x],axis=1)\n",
    "        \n",
    "#Delete duplicate columns\n",
    "df_D=df_D.loc[:, ~df_D.columns.duplicated()]\n",
    "\n",
    "#Write Dataframes to csv\n",
    "df_D.to_csv(\"df_clinical_measures_1_Date_Deces.csv\",index=False,encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "Path='D:\\StageMai2019\\Project\\data\\In\\'\n",
    "file_name1 = Path+'FullData.xlsx'\n",
    "file_name2=Path+'AdditionalData.xlsx'\n",
    "sheet_name='Sheet1'\n",
    "\n",
    "def Replace_Null_Ipp(file_name, sheet_name):\n",
    "    df = pd.read_excel(file_name, sheet_name)\n",
    "    df['IPP'] = df['IPP'].astype('str') \n",
    "    df['IPP']= df['IPP'].replace(['pasIPP','nan'],np.NaN)\n",
    "    return df\n",
    "\n",
    "df1=Replace_Null_Ipp(file_name1,sheet_name)\n",
    "df2=Replace_Null_Ipp(file_name2,sheet_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "Path=\"D:\\StageMai2019\\Project\\data\\In\\ \"\n",
    "\n",
    "file_name1 = Path+'FullData.xlsx'\n",
    "file_name2=Path+'AdditionalData.xlsx'\n",
    "sheet_name='Sheet1'\n",
    "\n",
    "def Replace_Null_Ipp(file_name, sheet_name):\n",
    "    df = pd.read_excel(file_name, sheet_name)\n",
    "    df['IPP'] = df['IPP'].astype('str') \n",
    "    df['IPP']= df['IPP'].replace(['pasIPP','nan'],np.NaN)\n",
    "    return df\n",
    "\n",
    "df1=Replace_Null_Ipp(file_name1,sheet_name)\n",
    "df2=Replace_Null_Ipp(file_name2,sheet_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "Path=\"D:\\\\StageMai2019\\\\Project\\\\data\\\\In\\\\\"\n",
    "\n",
    "file_name1 = Path+'FullData.xlsx'\n",
    "file_name2=Path+'AdditionalData.xlsx'\n",
    "sheet_name='Sheet1'\n",
    "\n",
    "def Replace_Null_Ipp(file_name, sheet_name):\n",
    "    df = pd.read_excel(file_name, sheet_name)\n",
    "    df['IPP'] = df['IPP'].astype('str') \n",
    "    df['IPP']= df['IPP'].replace(['pasIPP','nan'],np.NaN)\n",
    "    return df\n",
    "\n",
    "df1=Replace_Null_Ipp(file_name1,sheet_name)\n",
    "df2=Replace_Null_Ipp(file_name2,sheet_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib\n",
    "\n",
    "\n",
    "def Encode_Patients(df):\n",
    "    for index, row in df.iterrows():\n",
    "        if row['IPP'] is not None:\n",
    "             df.loc[index,'IPP_HASH']=hashlib.md5(str(row['IPP']).encode(\"utf-8\")).hexdigest()\n",
    "        else:\n",
    "             df.loc[index,'IPP_HASH']=hashlib.md5(str(row['NAME']+row['SURNAME']+row['DOB']).encode(\"utf-8\")).hexdigest()\n",
    "\n",
    "\n",
    "    df=df.drop(['PATIENT','REF_NAME','REF_ID770S4V3638','REF_SURNAME','NAME','SURNAME','NO','IPP','Column1'],1)\n",
    "    cols = df.columns.tolist()\n",
    "    cols = cols[-1:] + cols[:-1]\n",
    "    df = df[cols] \n",
    "    return df\n",
    "\n",
    "\n",
    "df1=Encode_Patients(df1)\n",
    "df2=Encode_Patients(df2)\n",
    "\n",
    "df1.to_excel(Path+'FullData_Hashed.xlsx',encoding='utf-8-sig',index=False)\n",
    "df2.to_excel(Path+'AdditionalData_Hashed.xlsx',encoding='utf-8-sig',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_name='FullData_Hashed.xlsx'\n",
    "\n",
    "df_A=pd.DataFrame()\n",
    "df_B=pd.DataFrame()\n",
    "df_C=pd.DataFrame()\n",
    "\n",
    "#create lists to hold headers & other variables\n",
    "HEADERS = []\n",
    "DATES_EXAM = []\n",
    "HEIGHTS=[]\n",
    "WEIGHTS_REF=[]\n",
    "WEIGHTS=[]\n",
    "BMIS=[]\n",
    "ALS=[]\n",
    "ALS_PARO=[]\n",
    "ALS_SALI =[]\n",
    "ALS_DEGL=[] \n",
    "ALS_ERCI=[] \n",
    "ALS_SGAS=[] \n",
    "ALS_AGAS=[] \n",
    "ALS_HABI=[] \n",
    "ALS_LITD=[]\n",
    "ALS_MARC=[] \n",
    "ALS_ESCA =[]\n",
    "ALS_DYSPNE=[] \n",
    "ALS_ORTHOPNE=[] \n",
    "ALS_INSR=[]\n",
    "DATES_RILUZ=[]\n",
    "DATES_PREVENT=[]\n",
    "CVF_ASSIS_THEO=[]\n",
    "CVL_ASSIS_THEO=[]\n",
    "All_cols=[]\n",
    "#group variables\n",
    "\n",
    "info=['IPP_HASH','SEX','DOB','DIAGPROBA','DATEDIAG','FIRSTSYMPTOM','LIEUDEB','AGE_DEBUT']\n",
    "clinical_measures_1=['DATEXAM','HEIGHT','WEIGHT_REF','WEIGHT','BMI','ALS','ALS_PARO','ALS_SALI','ALS_DEGL','ALS_ERCI','ALS_SGAS','ALS_AGAS','ALS_HABI','ALS_LITD','ALS_MARC','ALS_ESCA','ALS_ALS_dyspne','ALS_ALS_orthopne','ALS_INSR']\n",
    "clinical_measures_2=['DATE_PREVENT_PP','CVF_ASSIS_THEO_PP','CVL_ASSIS_THEO_PP']\n",
    "clinical_measures_riluz_1=['DATDRILU_L1']\n",
    "\n",
    "\n",
    "\n",
    "#Read CSV File\n",
    "df = pd.read_excel(file_name, sheet_name='Sheet1')\n",
    "\n",
    "#create a list of all the columns\n",
    "columns = list(df)\n",
    "\n",
    "#split columns list into headers and other variables\n",
    "for col in columns:\n",
    "    if col.startswith('DATEXAM'):\n",
    "        DATES_EXAM.append(col)\n",
    "    elif  col.startswith('HEIGHT'):\n",
    "        HEIGHTS.append(col)\n",
    "    elif col.startswith('WEIGHT_REF') :\n",
    "        WEIGHTS_REF.append(col)\n",
    "    elif  col.startswith('WEIGHT') :\n",
    "        WEIGHTS.append(col)\n",
    "    elif   col.startswith('BMI'): \n",
    "        BMIS.append(col)\n",
    "    elif  col.startswith('DATDRILU'):\n",
    "        DATES_RILUZ.append(col)\n",
    "    elif col.startswith('DATE_PREVENT'):\n",
    "        DATES_PREVENT.append(col)\n",
    "    elif col.startswith('CVF_ASSIS_THEO'):\n",
    "        CVF_ASSIS_THEO.append(col)\n",
    "    elif col.startswith('CVL_ASSIS_THEO'):\n",
    "        CVL_ASSIS_THEO.append(col)\n",
    "    elif  col.startswith('ALS'):\n",
    "        ##\n",
    "        if col.__contains__('PARO'):\n",
    "            ALS_PARO.append(col)\n",
    "        elif col.__contains__('SALI'):\n",
    "            ALS_SALI.append(col)\n",
    "        elif  col.__contains__('DEGL'):\n",
    "            ALS_DEGL.append(col)\n",
    "        elif  col.__contains__('ERCI'):\n",
    "            ALS_ERCI.append(col)\n",
    "        elif  col.__contains__('SGAS') :\n",
    "            ALS_SGAS.append(col)\n",
    "        elif  col.__contains__('AGAS'):\n",
    "            ALS_AGAS.append(col)\n",
    "        elif col.__contains__('HABI') :\n",
    "            ALS_HABI.append(col)\n",
    "        elif col.__contains__('LITD') :\n",
    "            ALS_LITD.append(col)\n",
    "        elif  col.__contains__('MARC') :\n",
    "            ALS_MARC.append(col)\n",
    "        elif  col.__contains__('ESCA'):\n",
    "            ALS_ESCA.append(col)\n",
    "        elif  col.__contains__('dyspne'):\n",
    "            ALS_DYSPNE.append(col)\n",
    "        elif col.__contains__('orthopne'):\n",
    "            ALS_ORTHOPNE.append(col)\n",
    "        elif col.__contains__('INSR'):\n",
    "            ALS_INSR.append(col)\n",
    "        else :\n",
    "            ALS.append(col)\n",
    "    else:\n",
    "        HEADERS.append(col)\n",
    "\n",
    "#For headers take into account only info \n",
    "\n",
    "HEADERS=list( x for x in info )\n",
    "\n",
    "#group column variables\n",
    "All_cols=[]\n",
    "All_cols.append(DATES_EXAM)\n",
    "All_cols.append(HEIGHTS)\n",
    "All_cols.append(WEIGHTS_REF)\n",
    "All_cols.append(WEIGHTS)\n",
    "All_cols.append(BMIS)\n",
    "All_cols.append(ALS)\n",
    "All_cols.append(ALS_PARO)\n",
    "All_cols.append(ALS_SALI)\n",
    "All_cols.append(ALS_DEGL)\n",
    "All_cols.append(ALS_ERCI)\n",
    "All_cols.append(ALS_SGAS)\n",
    "All_cols.append(ALS_AGAS)\n",
    "All_cols.append(ALS_HABI)\n",
    "All_cols.append(ALS_LITD)\n",
    "All_cols.append(ALS_MARC)\n",
    "All_cols.append(ALS_ESCA)\n",
    "All_cols.append(ALS_DYSPNE)\n",
    "All_cols.append(ALS_ORTHOPNE)\n",
    "All_cols.append(ALS_INSR)\n",
    "All_cols.append(DATES_RILUZ)\n",
    "All_cols.append(DATES_PREVENT)\n",
    "All_cols.append(CVF_ASSIS_THEO)\n",
    "All_cols.append(CVL_ASSIS_THEO)\n",
    "\n",
    "#remove empty lists from All_cols list if exist \n",
    "All_cols = [x for x in All_cols if x != []]\n",
    "\n",
    "#Create a final DF with modified columns\n",
    "for lst in All_cols:\n",
    "    df_x = pd.melt(df,\n",
    "                  id_vars=HEADERS,\n",
    "                  value_vars=lst,\n",
    "                  var_name=lst[0],\n",
    "                  value_name=lst[0]+'_VALUE')\n",
    "         #Concatenate DataFrames 1\n",
    "    if any(elem in lst for elem in clinical_measures_1):\n",
    "        df_A= pd.concat([df_A, df_x],axis=1)\n",
    "    if any(elem in lst for elem in clinical_measures_riluz_1):\n",
    "        #Concatenate DataFrames 2\n",
    "        df_B= pd.concat([df_B, df_x],axis=1)\n",
    "    if any(elem in lst for elem in clinical_measures_2):\n",
    "        df_C= pd.concat([df_C, df_x],axis=1)\n",
    "\n",
    "#Delete duplicate columns\n",
    "df_A= df_A.loc[:, ~df_A.columns.duplicated()]\n",
    "df_B= df_B.loc[:, ~df_B.columns.duplicated()]\n",
    "df_C= df_C.loc[:, ~df_C.columns.duplicated()]\n",
    "\n",
    "#Write Dataframes to csv\n",
    "df_A.to_csv(Path+\"df_clinical_measures_1.csv\",index=False,encoding='utf-8-sig')\n",
    "df_B.to_csv(Path+\"df_clinical_measures_1_Date_Riluzole.csv\",index=False,encoding='utf-8-sig')\n",
    "df_C.to_csv(Path+\"df_clinical_measures_2.csv\",index=False,encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name=Path+'AdditionalData_Hashed.xlsx'\n",
    "\n",
    "df_D=pd.DataFrame()\n",
    "\n",
    "#create lists to hold headers & other variables\n",
    "HEADERS = []\n",
    "DATES_DECES=[]\n",
    "All_cols=[]\n",
    "\n",
    "#group variables\n",
    "info=['IPP_HASH','SEX','DOB','DIAGPROBA','DATEDIAG','FIRSTSYMPTOM','LIEUDEB','AGE_DEBUT']\n",
    "clinical_measures_deces=['DATEDCD']\n",
    "\n",
    "\n",
    "#Read CSV File\n",
    "df = pd.read_excel(file_name, sheet_name='Sheet1')\n",
    "\n",
    "#create a list of all the columns\n",
    "columns = list(df)\n",
    "\n",
    "#split columns list into headers and other variables\n",
    "for col in columns:\n",
    "    if col.startswith('DATEDCD'):\n",
    "        DATES_DECES.append(col)\n",
    "    else:\n",
    "        HEADERS.append(col)\n",
    "\n",
    "#For headers take into account only info \n",
    "\n",
    "HEADERS=list( x for x in info )\n",
    "\n",
    "#group column variables\n",
    "All_cols=[]\n",
    "All_cols.append(DATES_DECES)\n",
    "\n",
    "#remove empty lists from All_cols list if exist \n",
    "All_cols = [x for x in All_cols if x != []]\n",
    "\n",
    "#Create a final DF with modified columns\n",
    "for lst in All_cols:\n",
    "    df_x = pd.melt(df,\n",
    "                  id_vars=HEADERS,\n",
    "                  value_vars=lst,\n",
    "                  var_name=lst[0],\n",
    "                  value_name=lst[0]+'_VALUE')\n",
    "         #Concatenate DataFrames\n",
    "    if any(elem in lst for elem in clinical_measures_deces):\n",
    "        df_D=pd.concat([df_D,df_x],axis=1)\n",
    "        \n",
    "#Delete duplicate columns\n",
    "df_D=df_D.loc[:, ~df_D.columns.duplicated()]\n",
    "\n",
    "#Write Dataframes to csv\n",
    "df_D.to_csv(Path+\"df_clinical_measures_1_Date_Deces.csv\",index=False,encoding='utf-8-sig')"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 2
}
